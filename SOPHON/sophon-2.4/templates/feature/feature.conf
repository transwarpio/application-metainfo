#Distribute data base
DDB=${service['distributed.database.type']}

<#if dependencies.SEARCH??>
<#assign search=dependencies.SEARCH searches=[] port=[]>
<#list search.roles.SEARCH_SERVER as role>
    <#if (search[role.id?c])??>
        <#assign searches += [role.hostname]>
        <#assign port += [search[role.id?c]['http.port']]>
    <#else>
        <#assign searches += [role['hostname']]>
        <#assign port += [search['http.port']]>
    </#if>
</#list>
<#assign eshosts = searches?join(",")>
feature.eshost = ${eshosts}
feature.esport = ${port[0]}
</#if>

#HDFS properties
hdfs.main.username=hdfs

spark.sql.warehouse.dir=${service['spark.sql.warehouse.dir']}
spark.master=yarn-client
spark.yarn.appMasterEnv.JAVA_HOME=/usr/java/jdk1.8.0_25
spark.executorEnv.JAVA_HOME=/usr/java/jdk1.8.0_25
spark.executor.instances=${service['spark.executor.num']}
spark.executor.cores=${service['spark.executor.core']}
<#if sophon.enable.kerberos>
spark.yarn.keytab=${service.keytab}
spark.yarn.principal=hive/${localhostname?lower_case}@${service.realm}
</#if>
spark.executor.memory=${service['spark.executor.memory']}
spark.driver.memory=${service['spark.driver.memory']}


# enable livy spark
enable.livy=${service['feature.enable.livy']}
task.pool.size=${service['feature.task.pool.size']}
task.max.concurrency=${service['feature.task.max.concurrency']}
task.timeout=${service['feature.task.timeout']}
feature.keytab=${service.keytab}
feature.principal=hive/${localhostname?lower_case}@${service.realm}

#hive properties
hive.host=${dependencies.INCEPTOR.roles.INCEPTOR_SERVER[0]['hostname']}
hive.port=${dependencies.INCEPTOR['hive.server2.thrift.port']}
hive.principal=hive/${dependencies.INCEPTOR.roles.INCEPTOR_SERVER[0]['hostname']}@${service.realm}
hive.kuser=hive/${localhostname?lower_case}@${service.realm}
hive.kerberos=${dependencies.INCEPTOR.auth}
hive.authentication=${dependencies.INCEPTOR['hive.server2.authentication']}
hive.ldap.username=${service['inceptor.ldap.username']}
hive.ldap.password=${service['inceptor.ldap.password']}
hive.hiveserver2=true
hive.database.prod=default
hive.keytab=${service.keytab}
hive.pool.size=64
hive.pool.timeout=3600
hive.label.numbuckets=30
hive.check.samples=100
hive.estable.numshards=10

#data-market gateway properties
app.datamarket-backend.name = datamart
app.datamarket-backend.gateway.use = true
app.gateway.url = http://${service.roles.SOPHON_GATEWAY[0]['hostname']}:${service['gateway.server.port']}

#etcd properties
common.etcd.use = true
