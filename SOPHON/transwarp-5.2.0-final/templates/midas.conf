# Use this keystore for the SSL certificate and key.
# livy.keystore =

# Specify the keystore password.
# livy.keystore.password =

# What host address to start the server on. By default, Livy will bind to all network interfaces.
# livy.server.host = 0.0.0.0

# What port to start the server on.
livy.server.port = ${service['livy.server.port']}

# What spark master Livy sessions should use.
livy.spark.master = yarn-client

# What spark deploy mode Livy sessions should use.
# livy.spark.deployMode =

# Time in milliseconds on how long Livy will wait before timing out an idle session.
# livy.server.session.timeout = 1h

# Number of sharable sessions defined on server
# livy.server.sharable.session.num = 15

# If livy should impersonate the requesting users when creating a new session.
# livy.impersonation.enabled = true

# Comma-separated list of Livy RSC jars. By default Livy will upload jars from its installation
# directory every time a session is started. By caching these files in HDFS, for example, startup
# time of sessions on YARN can be reduced.
# livy.jars =

# Comma-separated list of Livy REPL jars. By default Livy will upload jars from its installation
# directory every time a session is started. By caching these files in HDFS, for example, startup
# time of sessions on YARN can be reduced.
# livy.repl.jars =

# Location of PySpark archives. By default Livy will upload the file from SPARK_HOME, but
# by caching the file in HDFS, startup time of PySpark sessions on YARN can be reduced.
# livy.pyspark.archives =

# Location of the SparkR package. By default Livy will upload the file from SPARK_HOME, but
# by caching the file in HDFS, startup time of R sessions on YARN can be reduced.
# livy.sparkr.package =

# List of local directories from where files are allowed to be added to user sessions. By
# default it's empty, meaning users can only reference remote URIs when starting their
# sessions.
# livy.file.local-dir-whitelist =

# Whether to enable csrf protection, by default it is false. If it is enabled, client should add
# http-header "X-Requested-By" in request if the http method is POST/DELETE/PUT/PATCH.
# livy.server.csrf_protection.enabled =

# Whether to enable HiveContext in livy interpreter, if it is true hive-site.xml will be detected
# on user request and then livy server classpath automatically.
# livy.repl.enableHiveContext =

# Recovery mode of Livy. Possible values:
# off: Default. Turn off recovery. Every time Livy shuts down, it stops and forgets all sessions.
# recovery: Livy persists session info to the state store. When Livy restarts, it recovers
#           previous sessions from the state store.
# Must set livy.server.recovery.state-store and livy.server.recovery.state-store.url to
# configure the state store.
# livy.server.recovery.mode = off

# Where Livy should store state to for recovery. Possible values:
# <empty>: Default. State store disabled.
# filesystem: Store state on a file system.
# zookeeper: Store state in a Zookeeper instance.
# livy.server.recovery.state-store =

# For filesystem state store, the path of the state store directory. Please don't use a filesystem
# that doesn't support atomic rename (e.g. S3). e.g. file:///tmp/livy or hdfs:///.
# For zookeeper, the address to the Zookeeper servers. e.g. host1:port1,host2:port2
# livy.server.recovery.state-store.url =

# If Livy can't find the yarn app within this time, consider it lost.
livy.server.yarn.app-lookup-timeout = 8000s

# How often Livy polls YARN to refresh YARN app state.
# livy.server.yarn.poll-interval = 1s

# WARMING!!! following are for developing and debug use, do not use them in production environment
# do not create new process for session, make debug easier
# livy.rsc.client.do_not_use.run_driver_in_process=false

# develop mode, will do extra validation
# livy.server.dev-mode=false

# zookeeper license cluster
<#assign license_servers=[]>
<#list dependencies.LICENSE_SERVICE.roles.LICENSE_NODE as server>
    <#assign license_servers += [(server.hostname + ":" + dependencies.LICENSE_SERVICE[server.hostname]["zookeeper.client.port"])]>
</#list>
livy.server.security.license.url = ${license_servers?join(",")}

# redis server for cache
livy.cache.type=${service['livy.cache.type']}
livy.cache.host=${service.roles.SOPHON_REDIS[0].hostname}
livy.cache.port=${service['midas.redis.port']}

livy.scheduler.host=${service.roles.SOPHON_SCHEDULER[0].hostname}
livy.scheduler.port=${service['livy.scheduler.port']}

livy.storage.basedir=${service['livy.storage.basedir']}

# zookeeper license mode
livy.server.security.license.type = sophon
livy.server.user.manager.open = ${service['livy.server.user.manager.open']}
livy.server.user.manager.component = ${service.sid}

# hdfs jars
livy.hdfsjars.enable = true
livy.hdfs.jars = /tmp/.sophonJars

# kerberos
<#if service.auth = "kerberos">
livy.server.auth.type = ${service.auth}
livy.server.launch.kerberos.principal = hive/${localhostname?lower_case}@${service.realm}
livy.server.launch.kerberos.keytab = ${service.keytab}
</#if>
# custom configurations
<#if service['midas.conf']??>
<#list service['midas.conf'] as key, value>
${key}=${value}
</#list>
</#if>
#TxSql dependency
<#if dependencies.TXSQL??>
livy.jdbc.username = ${service['livy.jdbc.username']}
livy.jdbc.password = ${service['livy.jdbc.password']}
    <#assign livy_jdbc_urls = []/>
    <#list dependencies.TXSQL.roles['TXSQL_SERVER'] as role>
      <#assign livy_jdbc_urls += ["jdbc:mysql://" + role.hostname + ':' + dependencies.TXSQL['mysql.rw.port'] + "/metastore_" + service.sid + "?useUnicode=true&characterEncoding=UTF-8"]>
    </#list>
<#assign livy_jdbc_url=livy_jdbc_urls?join(",")>
livy.jdbc.url = ${livy_jdbc_url}
</#if>

