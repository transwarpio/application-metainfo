#ES properties
mirror.eshost = ${dependencies.SEARCH.roles.SEARCH_SERVER[0]['hostname']}
mirror.esport = ${dependencies.SEARCH['http.port']}

#HDFS properties
hdfs.main.username=hdfs

#Distribute data base
DDB=${service['mirror.distributed.database.type']}

#inceptor properties
inceptor.host=${dependencies.INCEPTOR.roles.INCEPTOR_SERVER[0]['hostname']}
inceptor.port=${dependencies.INCEPTOR['hive.server2.thrift.port']}
inceptor.kerberos=false
inceptor.hiveserver2=true
inceptor.database.prod=default
inceptor.realm=TDH
inceptor.keytab=/tmp/inceptor.keytab
inceptor.pool.size=64
inceptor.pool.timeout=3600
inceptor.label.numbuckets=30
inceptor.check.samples=100
inceptor.estable.numshards=10

mirror.superuser.username=${service['mirror.superuser.username']}
mirror.superuser.password=${service['mirror.superuser.password']}

spark.sql.warehouse.dir=${service['spark.sql.warehouse.dir']}
spark.master=yarn-client
spark.yarn.appMasterEnv.JAVA_HOME=/usr/java/jdk1.8.0_25
spark.executorEnv.JAVA_HOME=/usr/java/jdk1.8.0_25

workflow.workspace.name=mirror_test
workflow.domain.id=0
mirror.host=${service.roles.MIRROR_USERPROFILE_BACKEND[0]['hostname']}
task.pool.size=${service['task.pool.size']}
task.max.concurrency=${service['task.pool.size']}
task.timeout=${service['task.timeout']}
mirror.execute.cycle=${service['mirror.execute.cycle']}
